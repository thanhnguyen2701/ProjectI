import os, json, re
from tqdm import tqdm
import chromadb
from chromadb.utils import embedding_functions
from tiktoken import get_encoding
from dotenv import load_dotenv

load_dotenv()

os.environ["CHROMA_OPENAI_API_KEY"] = os.getenv("OPENAI_API_KEY")

# ƒê∆∞·ªùng d·∫´n t·ªõi file JSONL b·∫°n ƒë√£ t·∫°o ·ªü b∆∞·ªõc tr∆∞·ªõc
jsonl_path = r"C:\Users\FPTSHOP\2025.1\ProjectI\sample-smart-contract-dataset\processed_documents.jsonl"
chroma_path = r"C:\Users\FPTSHOP\2025.1\ProjectI\chroma_db"

# ---------------------
# 1Ô∏è‚É£ H√ÄM CHIA CHUNK
# ---------------------
def chunk_text(text, max_tokens=500, overlap=100):
    enc = get_encoding("cl100k_base")  # tokenizer c·ªßa OpenAI
    tokens = enc.encode(text)
    chunks = []
    start = 0
    while start < len(tokens):
        end = start + max_tokens
        chunk_tokens = tokens[start:end]
        chunks.append(enc.decode(chunk_tokens))
        start += max_tokens - overlap
    return chunks

# ---------------------
# 2Ô∏è‚É£ KH·ªûI T·∫†O CHROMA
# ---------------------
client = chromadb.PersistentClient(path=chroma_path)

# S·ª≠ d·ª•ng embedding c·ªßa OpenAI (c·∫ßn API key)
openai_ef = embedding_functions.OpenAIEmbeddingFunction(model_name="text-embedding-3-small")

collection = client.get_or_create_collection(
    name="smart_contract_audits",
    embedding_function=openai_ef
)

# ---------------------
# 3Ô∏è‚É£ ƒê·ªåC FILE JSONL
# ---------------------
documents = []
with open(jsonl_path, "r", encoding="utf-8") as f:
    for line in f:
        doc = json.loads(line)
        if doc.get("content"):
            documents.append(doc)

print(f"üìÑ ƒê·ªçc {len(documents)} t√†i li·ªáu g·ªëc.")

# ---------------------
# 4Ô∏è‚É£ CHUNK + TH√äM V√ÄO CHROMA
# ---------------------
ids, texts, metadatas = [], [], []

for i, doc in enumerate(tqdm(documents)):
    chunks = chunk_text(doc["content"], max_tokens=500, overlap=100)
    for j, chunk in enumerate(chunks):
        ids.append(f"{doc['id']}_{j}")
        texts.append(chunk)
        metadatas.append({
            "id": doc["id"],
            "title": doc["title"],
            "impact": doc["impact"],
            "firm": doc["firm"],
            "protocol": doc["protocol"],
            "date": doc["date"],
            "source": doc["source"]
        })

# ---------------------
# 5Ô∏è‚É£ CHIA NH·ªé KHI TH√äM V√ÄO CHROMA
# ---------------------
batch_size = 100  # S·ªë chunk x·ª≠ l√Ω m·ªói l·∫ßn (b·∫°n c√≥ th·ªÉ tƒÉng l√™n 200 n·∫øu mu·ªën nhanh h∆°n)
for i in range(0, len(texts), batch_size):
    batch_ids = ids[i:i+batch_size]
    batch_texts = texts[i:i+batch_size]
    batch_meta = metadatas[i:i+batch_size]
    collection.add(
        ids=batch_ids,
        documents=batch_texts,
        metadatas=batch_meta
    )
    print(f"‚úÖ ƒê√£ th√™m {i + len(batch_texts)} / {len(texts)} chunks")

print(f"‚úÖ ƒê√£ th√™m {len(texts)} chunks v√†o ChromaDB.")
print(f"üíæ Database l∆∞u t·∫°i: {chroma_path}")
